{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "# # 1 means: only reload modules marked with \"%aimport\"\n",
    "# # 2 means: reload all modules\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#thread management\n",
    "from Queue import Queue\n",
    "from threading import Thread,Lock\n",
    "from collections import deque\n",
    "\n",
    "#Picamera\n",
    "import picamera as pc\n",
    "from picamera.array import PiRGBArray\n",
    "\n",
    "#image manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 #opencv\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#general modules\n",
    "import time,datetime\n",
    "import pickle\n",
    "import sys, warnings\n",
    "import copy\n",
    "from PIL import Image\n",
    "\n",
    "#for fitting train-direction model\n",
    "from scipy.optimize import curve_fit\n",
    "import math\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Picamera and Capture Frames from Video Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Video_Camera(Thread):\n",
    "    def __init__(self,fps,width,height,vflip,hflip,mins):\n",
    "        self.fps=fps\n",
    "        self.width=width\n",
    "        self.height=height\n",
    "        self.vflip=vflip\n",
    "        self.hflip=hflip\n",
    "        self.mins=mins\n",
    "        #Deque storage data structures\n",
    "        #Set max length of X minutes to prevent memory errors\n",
    "        self.input_deque=deque(maxlen=fps*mins*60) \n",
    "        #start the thread, deamon and kill switch\n",
    "        super(Video_Camera, self).__init__()\n",
    "        self.daemon = True\n",
    "        self.kill_all_threads= False\n",
    "        print self, 'created'\n",
    "        #Initialize camera and video stream\n",
    "        self.initialize_camera()\n",
    "        self.initialize_video_stream()\n",
    "        print 'Camera and video stream initialized'\n",
    "        \n",
    "    def initialize_camera(self):\n",
    "        self.camera = pc.PiCamera(\n",
    "            resolution=(self.width,self.height), \n",
    "            framerate=int(self.fps))\n",
    "        #Set camera properties\n",
    "        self.camera.vflip = self.vflip\n",
    "        self.camera.hflip = self.hflip\n",
    "        self.apply_camera_day_settings()\n",
    "        \n",
    "    def initialize_video_stream(self):\n",
    "        self.rawCapture = pc.array.PiRGBArray(self.camera, size=self.camera.resolution) \n",
    "        self.stream = self.camera.capture_continuous(self.rawCapture,\n",
    "             format=\"bgr\", \n",
    "             use_video_port=True)\n",
    "    \n",
    "    def apply_camera_day_settings(self):\n",
    "        self.camera.exposure_mode = 'auto'\n",
    "        self.camera.contrast=0\n",
    "        self.camera.brightness=50\n",
    "        self.camera.exposure_compensation=0\n",
    "        #assign a custom flag\n",
    "        self.camera.operating_mode='day'\n",
    "\n",
    "    def apply_camera_night_settings(self):\n",
    "        self.camera.exposure_mode = 'auto'\n",
    "        self.camera.contrast=20\n",
    "        self.camera.brightness=90\n",
    "        self.camera.exposure_compensation=6\n",
    "        #assign a custom flag\n",
    "        self.camera.operating_mode='night'\n",
    "        \n",
    "    def run(self):\n",
    "        #This method is run when the command start() is given to the thread\n",
    "        print 'Video stream is now being captured'\n",
    "        for f in self.stream:\n",
    "            #add frame with timestamp to input queue\n",
    "            self.input_deque.append({\n",
    "                'time':time.time(),\n",
    "                'frame_raw':f.array})\n",
    "            \n",
    "            #remove the frame from the stream \n",
    "            self.rawCapture.truncate(0)\n",
    "            \n",
    "            if self.kill_all_threads==True:\n",
    "                print self, 'terminated'\n",
    "                break\n",
    "                \n",
    "                \n",
    "#Initialize Video_Camera Thread\n",
    "video_camera = Video_Camera(fps=5,\n",
    "                            width=384,\n",
    "                            height=216,\n",
    "                            vflip=True,\n",
    "                            hflip=False,\n",
    "                            mins=1)\n",
    "#Begin capturing raw video and store data in the input_queue\n",
    "video_camera.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the input stream to file for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Save input queue to file\n",
    "save_stream_to_file=False\n",
    "if save_stream_to_file==True:\n",
    "    print video_camera.input_deque[0]\n",
    "    pickle.dump(video_camera.input_deque,open(\"persisted_input_queue_20160624_b\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load input queue from file\n",
    "load_stream_from_file=True\n",
    "if load_stream_from_file==True:\n",
    "    pickle_object=pickle.load( open(\"persisted_input_queue_20160624_b\",\"rb\"))\n",
    "    video_camera.kill_all_threads=True\n",
    "    time.sleep(1)\n",
    "    video_camera.input_deque=pickle_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a background subtractor to help detect motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Mask():\n",
    "    def __init__(self,fps):\n",
    "        self.fps=fps\n",
    "        self.mask=None\n",
    "        \n",
    "    def make_mask(self,mask_type):\n",
    "        if mask_type=='KNN':\n",
    "            #K-nearest neigbours - based Background/Foreground Segmentation Algorithm.\n",
    "            self.bgsKNN_history=int((1.0/self.fps)*40.0) #length of history in seconds\n",
    "            self.bgsKNN_d2T=400 #distance to threshold\n",
    "            self.bgsKNN_dS=False #detect shadows\n",
    "            #create and return mask\n",
    "            self.mask=self.make_KNN_mask(self.bgsKNN_history,self.bgsKNN_d2T,self.bgsKNN_dS)\n",
    "        elif mask_type=='MOG2':\n",
    "            #Gaussian Mixture-based Background/Foreground Segmentation Algorithm - Improved!\n",
    "            self.detectShadows = True\n",
    "            self.mask=self.make_MOG2_mask(self.detectShadows)\n",
    "        else:\n",
    "            print 'Error: Incorrect Mask Type Chosen!'\n",
    "        return self.mask\n",
    "    \n",
    "    def make_KNN_mask(self,bgsKNN_history,bgsKNN_d2T,bgsKNN_dS):\n",
    "        mask = cv2.createBackgroundSubtractorKNN(\\\n",
    "            history=bgsKNN_history,\\\n",
    "            dist2Threshold=bgsKNN_d2T,\\\n",
    "            detectShadows=bgsKNN_dS)\n",
    "        return mask\n",
    "        \n",
    "    def make_MOG2_mask(self,detectShadows):\n",
    "        mask = cv2.createBackgroundSubtractorMOG2(detectShadows = detectShadows)\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the captured frames, dynamically Vary Camera Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Video_Sensor(Thread):\n",
    "    def __init__(self,video_camera,mask_type):\n",
    "        #Assign objects from the video camera class\n",
    "        self.video_camera=video_camera\n",
    "        self.camera=self.video_camera.camera\n",
    "        self.input_deque=self.video_camera.input_deque\n",
    "        self.fps=self.video_camera.fps\n",
    "        self.mins=self.video_camera.mins\n",
    "        #Deque storage data structures\n",
    "        #Set max length of X minutes to prevent memory errors\n",
    "        self.output_deque=deque(maxlen=self.fps*self.mins*60) \n",
    "        #start the thread, deamon and kill switch\n",
    "        super(Video_Sensor, self).__init__()\n",
    "        self.daemon = True\n",
    "        self.kill_all_threads= False\n",
    "        print self, 'created'\n",
    "        #Assign mask objects and create mask\n",
    "        self.mask_type=mask_type\n",
    "        self.create_mask()\n",
    "        \n",
    "    def create_mask(self):\n",
    "        #create mask_object for future generations of masks\n",
    "        self.mask_object=Mask(fps=video_camera.fps)\n",
    "        self.mask=self.mask_object.make_mask(self.mask_type)\n",
    "        print '%s created, with mask_type: %s'%(self.mask_object, self.mask_type)\n",
    "        \n",
    "    def vary_camera_settings(self,frame_raw):\n",
    "        # Dynamically Vary Camera Settings\n",
    "        intensity_mean=frame_raw.ravel().mean() #8 bit camera\n",
    "        #adjust camera properties dynamically if needed, then reset mask\n",
    "        if ((intensity_mean < (255.0/8) ) & (self.camera.operating_mode=='day')):\n",
    "            self.video_camera.apply_camera_night_settings()\n",
    "            time.sleep(1)\n",
    "            self.mask=self.mask_object.make_mask(self.mask_type)\n",
    "            print 'Day Mode Activated - Camera'\n",
    "        if ((intensity_mean < (255.0*(3/4)) ) & (self.camera.operating_mode=='night')):\n",
    "            self.video_camera.apply_camera_day_settings()\n",
    "            time.sleep(1)\n",
    "            self.mask=self.mask_object.make_mask(self.mask_type)\n",
    "            print 'Night Mode Activated - Camera'\n",
    "        return intensity_mean,self.mask\n",
    "\n",
    "    def apply_mask_and_decrease_noise(self,frame_raw):\n",
    "        #apply the background subtraction mask\n",
    "        frame_motion = self.mask.apply(frame_raw)\n",
    "        #apply morphology mask to decrease noise\n",
    "        frame_motion_output = cv2.morphologyEx(\n",
    "            frame_motion,\\\n",
    "            cv2.MORPH_OPEN,\\\n",
    "            kernel=np.ones((2,2),np.uint8))\n",
    "        return frame_motion_output\n",
    "        \n",
    "    def run(self):\n",
    "        print 'Video stream is now being processed, and camera settings varied if needed'\n",
    "        while self.kill_all_threads!=True:\n",
    "            try:\n",
    "                #obtain raw data, apply background mask and decrease noise\n",
    "                data = self.input_deque.popleft()\n",
    "                frame_raw=data['frame_raw']\n",
    "                frame_motion=self.apply_mask_and_decrease_noise(frame_raw)\n",
    "\n",
    "                # Dynamically Vary Camera Settings, update mask if needed\n",
    "                intensity_mean,self.mask=\\\n",
    "                    self.vary_camera_settings(frame_raw)\n",
    "\n",
    "                #save these frames as a dict to an output queue\n",
    "                self.output_deque.append({\\\n",
    "                    'frame_raw':frame_raw,\\\n",
    "                    'frame_motion':frame_motion,\n",
    "                    'time':data['time'],\n",
    "                    'intensity_mean':intensity_mean})\n",
    "\n",
    "            except IndexError:\n",
    "                #index error occurs when the input_queue is empty\n",
    "                time.sleep(1/self.fps)\n",
    "                pass\n",
    "        \n",
    "#Initialize Video_Sensor Thread\n",
    "video_sensor = Video_Sensor(video_camera=video_camera,\n",
    "                            mask_type='KNN')\n",
    "video_sensor.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a history dataframe to persist data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class History():\n",
    "    def __init__(self,fps):\n",
    "        self.len_history=int(fps*600)\n",
    "        self.columns=['time','left_roi','middle_roi','right_roi',\\\n",
    "                 'motion_detected','train_detected','direction'] \n",
    "        \n",
    "    def setup_history(self):\n",
    "        #create pandas dataframe that contains  column information\n",
    "        self.history = pd.DataFrame.from_records(\\\n",
    "            np.zeros((self.len_history,len(self.columns))),\n",
    "            index=np.arange(self.len_history),\n",
    "            columns=self.columns)\n",
    "        print 'History dataframe created with columns:\\n', self.columns\n",
    "        return self.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Detector Worker - Includes video plotter, direction detector and frame sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Detector_Worker(Thread):\n",
    "    def __init__(self,video_sensor,video_detector):\n",
    "        self.video_sensor=video_sensor\n",
    "        self.video_detector=video_detector\n",
    "        self.history=self.video_detector.history\n",
    "        self.frame_sampler_buffer=self.video_detector.frame_sampler_buffer\n",
    "        self.all_rois=self.video_detector.all_rois\n",
    "        self.intensity_threshold=self.video_detector.motion_threshold\n",
    "        self.fps=self.video_sensor.fps\n",
    "        self.motion_threshold=self.video_detector.motion_threshold\n",
    "        self.time_threshold=self.video_detector.time_threshold\n",
    "        #start the thread, deamon and kill switch\n",
    "        super(Detector_Worker, self).__init__()\n",
    "        self.daemon = True\n",
    "        self.kill_all_threads= False\n",
    "        print self, 'created'\n",
    "    \n",
    "    '''\n",
    "    UTILITY FUNCTIONS (below)\n",
    "    '''\n",
    "    \n",
    "    def run(self):\n",
    "        if self.kill_all_threads!=True:\n",
    "            time.sleep(0.5)\n",
    "\n",
    "    def get_history_snapshot(self):\n",
    "            #grab and process the raw data\n",
    "            self.history_snapshot_0=(self.history.left_roi / 255.0).tolist()\n",
    "            self.history_snapshot_1=(self.history.middle_roi / 255.0).tolist()\n",
    "            self.history_snapshot_2=(self.history.right_roi /255.0).tolist()\n",
    "            self.history_snapshot_motion_events=(self.history.motion_detected.tolist())\n",
    "            self.history_snapshot_detection_events=(self.history.train_detected.tolist())\n",
    "            self.history_snapshot_direction_events=(self.history.direction.tolist())\n",
    "\n",
    "            #obtain the average values from the motion of the ROIs\n",
    "            self.history_snapshot_mean=[]\n",
    "            for i in range(0,len(self.history_snapshot_0)):\n",
    "                self.history_snapshot_mean.append((\\\n",
    "                    self.history_snapshot_0[i]+self.history_snapshot_1[i]+self.history_snapshot_2[i])/3.0)\n",
    "\n",
    "            #import time and convert relative to relative_time\n",
    "            self.original_time_xaxis=self.history.time.tolist()\n",
    "            #set relative time to the most recent time in the time series\n",
    "            self.relative_time=max(self.original_time_xaxis)\n",
    "            self.time_string=datetime.datetime.fromtimestamp(\\\n",
    "                self.relative_time).strftime('%Y:%m:%d:%H:%M:%S')\n",
    "            #normalize the time_xaxis to relative_time (by copying the original)\n",
    "            self.time_xaxis=list(self.original_time_xaxis) \n",
    "            self.time_xaxis[:] = [x - self.relative_time for x in self.time_xaxis] \n",
    "\n",
    "    def identify_frame_of_train_detection(self):\n",
    "        time_of_train=None\n",
    "        for i in range(0,len(self.history_snapshot_detection_events)):\n",
    "            if self.history_snapshot_detection_events[i]==True:\n",
    "                #check if the timestamp is the most recent time\n",
    "                if  self.original_time_xaxis[i] > time_of_train : \n",
    "                    time_of_train=self.original_time_xaxis[i]\n",
    "                    train_detected_flag=True\n",
    "        #if there is no train_detection event found, return last frame in deque\n",
    "        if time_of_train!=None:\n",
    "            return time_of_train, train_detected_flag\n",
    "        else:\n",
    "            train_detected_flag=False\n",
    "            return max(self.original_time_xaxis),train_detected_flag\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    VIDEO PLOTTER (below)\n",
    "    '''\n",
    "    def video_plotter(self,total_time_in_plot):\n",
    "        #refresh the video_detector_worker history snapshot\n",
    "        self.get_history_snapshot()\n",
    "        #determine time length of plot\n",
    "        self.total_time_in_plot=total_time_in_plot\n",
    "        plt.figure(figsize=(15,7.5))\n",
    "        plt.ylim([0,1.1])\n",
    "        plt.xlim([-1*self.total_time_in_plot/self.fps,0])\n",
    "        plt.xlabel(('Time: relative to %s (seconds)')%(self.time_string),size=20)\n",
    "        plt.ylabel('Relative Motion (1 is high)', size=20)\n",
    "        #add series to the plot\n",
    "        plt.plot(self.time_xaxis,self.history_snapshot_0,'m',\\\n",
    "                marker='o', linewidth=2,label=\"ROI: South\")\n",
    "        plt.plot(self.time_xaxis,self.history_snapshot_1,'g',\\\n",
    "                marker='o', linewidth=2,label=\"ROI: Middle\")\n",
    "        plt.plot(self.time_xaxis,self.history_snapshot_2,'b',\\\n",
    "                marker='o', linewidth=2,label=\"ROI: North\")\n",
    "        plt.plot(self.time_xaxis,self.history_snapshot_motion_events,color='0.75',\\\n",
    "                linewidth=2,label=\"Motion Detected\")\n",
    "        plt.plot(self.time_xaxis,self.history_snapshot_detection_events,'k',\\\n",
    "                linewidth=3, label=\"Train Detected\")\n",
    "        #draw threshold line\n",
    "        plt.axhline(y=(self.motion_threshold/255.0), xmin=0, xmax=1, linewidth=1,\\\n",
    "                    color = 'r', label=\"Detection Threshold\")\n",
    "        #draw legend and title\n",
    "        plt.legend(loc='upper left',prop={'size':12})\n",
    "        plt.title(\"Video Detection \\n Requires: %s motion, for %s seconds\"\n",
    "                  % (str(round((self.motion_threshold/255.0),2)),\\\n",
    "                     str(self.time_threshold/self.fps)),size=20)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "    '''\n",
    "    FRAME SAMPLER (below)\n",
    "    '''\n",
    "    def draw_rois(self,frame):\n",
    "        for v in self.all_rois:\n",
    "            cv2.rectangle(frame,\n",
    "                (v[0]),(v[1]),\n",
    "                (255,0,0),#color\n",
    "                2)#thickness\n",
    "        return frame\n",
    "    \n",
    "    def get_frame_by_timestamp_from_frame_sampler_buffer(self,timestamp):\n",
    "        for i in range(0,len(self.frame_sampler_buffer)-1):\n",
    "            frame_time=self.frame_sampler_buffer[i]['time']\n",
    "            frame_time_next=self.frame_sampler_buffer[i+1]['time']\n",
    "            #check if the timestamp is inbetween the two frames\n",
    "            if (timestamp>=frame_time) & (timestamp<=frame_time_next):\n",
    "                return self.frame_sampler_buffer[i]\n",
    "        #if no frame is found, grab the most recent frame\n",
    "        return self.frame_sampler_buffer[-1]\n",
    "    \n",
    "    def frame_sampler(self):\n",
    "        #refresh the video_detector_worker history snapshot\n",
    "        self.get_history_snapshot()\n",
    "        try:\n",
    "            #identify if recent frame has a picture of the train\n",
    "            timestamp,train_detected_flag = self.identify_frame_of_train_detection()\n",
    "            images=self.get_frame_by_timestamp_from_frame_sampler_buffer(timestamp)\n",
    "            if train_detected_flag==True:\n",
    "                print 'Analyzing train detection event at frame:',i\n",
    "            else:\n",
    "                print 'Analyzing most recent frame'\n",
    "\n",
    "            #create plot\n",
    "            plt.figure(figsize=(16,8))\n",
    "            #adjust raw image to RGB and plot\n",
    "            plt.subplot(2,2,1)\n",
    "            frame_raw=images['frame_raw']\n",
    "            plt.imshow(np.flipud(frame_raw[:, :, ::-1]))\n",
    "            #draw on the ROI of interest and plot\n",
    "            plt.subplot(2,2,2)\n",
    "            frame_raw=self.draw_rois(images['frame_raw'].copy())\n",
    "            plt.imshow(np.flipud(frame_raw[:, :, ::-1]))\n",
    "            #plot masked iamged\n",
    "            plt.subplot(2,2,3)\n",
    "            frame_motion=images['frame_motion']\n",
    "            plt.imshow(np.flipud(\\\n",
    "                        255-frame_motion),\\\n",
    "                       cmap='Greys',  interpolation='nearest')\n",
    "            #draw on the ROI of interest and plot\n",
    "            plt.subplot(2,2,4)\n",
    "            frame_motion=self.draw_rois(images['frame_motion'])\n",
    "            plt.imshow(np.flipud(\\\n",
    "                        255-frame_motion),\\\n",
    "                       cmap='Greys',  interpolation='nearest')\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "        except:\n",
    "            print 'No images in frame sampler buffer'\n",
    "      \n",
    "    \n",
    "    '''\n",
    "    TRAIN DIRECTION (below)\n",
    "    '''     \n",
    "    def extract_data_in_time_range(self,time_before,time_after,event_time):\n",
    "        #find the indices that correspond to the time range\n",
    "        indices = [i for i, x in enumerate(self.original_time_xaxis)\\\n",
    "                   if ((x <= (event_time+time_after)) and (x >= (event_time-time_before))) ]\n",
    "\n",
    "        #extract the data in a 5 element array from history that correspond to these indices\n",
    "        data=[self.original_time_xaxis,\n",
    "             self.history_snapshot_0,\n",
    "             self.history_snapshot_1,\n",
    "             self.history_snapshot_2,\n",
    "             self.history_snapshot_detection_events]\n",
    "        extracted_data=[]\n",
    "        for array in data:\n",
    "            extracted_data.append([ array[i] for i in indices])\n",
    "        return extracted_data\n",
    "    \n",
    "    def calculate_time_of_arrival(self,extracted_data,j,event_time):\n",
    "        t,xdata,ydata=self.import_data_from_roi(extracted_data,j,event_time)\n",
    "        #attempt to fit the curve with sigmoid\n",
    "        curve_fit_possible,popt,pcov=self.km_map_wth_sigmoid(xdata,ydata)\n",
    "        #plot the information\n",
    "        x_curve = np.linspace(xdata.min(),xdata.max(), len(xdata))\n",
    "        #if the curve can be fit accurately, use the fit funciotn\n",
    "        if curve_fit_possible == True:\n",
    "            try:\n",
    "                y_curve = self.curve_func(xdata, *popt)\n",
    "                km= (-math.log(2*-popt[0]-popt[2])) / popt[1]\n",
    "            except:\n",
    "                #if there are problems with a log of a negative number\n",
    "                print 'cannot take a log of a neg number'\n",
    "                km=self.alternate_km_map(ydata,t,event_time)\n",
    "                y_curve=ydata\n",
    "        else:\n",
    "            #get the max value from the ROI sensor over the time frame stored\n",
    "            km=self.alternate_km_map(ydata,t,event_time)\n",
    "            #set the model y_curve to exactly match the data\n",
    "            y_curve=ydata\n",
    "        return km,y_curve,x_curve,xdata,ydata,t\n",
    "    \n",
    "    def import_data_from_roi(self,extracted_data,i,event_time):\n",
    "        t=extracted_data[0]\n",
    "        roi_of_interest=extracted_data[i]\n",
    "        xdata=np.array([t[i] - event_time for i in range(0,len(t))])\n",
    "        ydata=[roi_of_interest[i] for i in range(0,len(roi_of_interest))]\n",
    "        return t,xdata,ydata\n",
    "\n",
    "    def plot_for_train_direction(self,t_adjusted,ydata,x_curve,y_curve,j):\n",
    "        color=['mp','bs','g^']\n",
    "        color_model=['m','b','g']\n",
    "        label_raw=['ROI: South','ROI: Middle','ROI: North']\n",
    "        label_model=['ROI: South - FIT','ROI: Middle - FIT','ROI: North - FIT']\n",
    "        #plot raw data\n",
    "        plt.plot(t_adjusted, ydata, color[j-1],label=label_raw[j-1])\n",
    "        #plot modelled curve\n",
    "        plt.plot(x_curve, y_curve, color_model[j-1],label=label_model[j-1])\n",
    "\n",
    "    def curve_func(self,x, a, b,c):\n",
    "        #Sigmoid function\n",
    "        return -a/(c+ np.exp(b * -x))\n",
    "    \n",
    "    def decide_train_direction(self,time_of_arrival):\n",
    "        if time_of_arrival[0] < time_of_arrival[-1]:\n",
    "            train_direction='NORTH'\n",
    "        else:\n",
    "            train_direction='SOUTH'\n",
    "        return train_direction\n",
    "    \n",
    "    def format_entire_plot_for_train_direction(self,d,t_adjusted,ydata,x_curve,y_curve,\\\n",
    "        time_span_before,time_span_after,train_direction,time_string,time_of_arrival):\n",
    "        #plot the detector spike then show plot\n",
    "        plt.plot(t_adjusted,d,'k',label='Train Detection Event')\n",
    "        plt.legend(loc='upper left',prop={'size':12})\n",
    "        plt.xlabel('Time: relative to now (seconds)',size=20)\n",
    "        plt.ylabel('Relative Motion (1 is high)', size=20)\n",
    "        plt.title((\"Train Detected Going: %s \\n Plot of: %s sec to %s sec after train detected \\nAt: %s\")\\\n",
    "                      % (str(train_direction),str(time_span_before), str(time_span_after),\\\n",
    "                      str(time_string)),size=20)\n",
    "        plt.figtext(.35, -.1, 'ROI South, time of arrival:'+str(time_of_arrival[0])+\\\n",
    "                    '\\nROI Middle, time of arrival:'+str(time_of_arrival[1])+\\\n",
    "                    '\\nROI North, time of arrival:'+str(time_of_arrival[2]),size=20)\n",
    "        \n",
    "    def clean_extracted_data(self,extracted_data,event_time,intensity_threshold):\n",
    "        if extracted_data != None:\n",
    "            #make a copy of the extracted data\n",
    "            extracted_data_original=list(extracted_data)\n",
    "            #clean the extracted_data values in the ROIs\n",
    "            #(prevent dropping back to zero, and normalize to 100)\n",
    "            for i in range (1,4):\n",
    "                #walk through all values\n",
    "                detection_limit_passed = False\n",
    "                for j in range(0,len(extracted_data[i])):\n",
    "                    #normalize to 100\n",
    "                    extracted_data[i][j]=((extracted_data[i][j]))\n",
    "                    #prevent the values from dropping back to zero\n",
    "                    if j!=0:\n",
    "                        #check the values against the video intensity threshold\n",
    "                        if extracted_data[i][j] > ((intensity_threshold)):\n",
    "                            variance_allowed=0.05\n",
    "                            #enforce that the value of the next item cannot drop by more than 10%\n",
    "                            if extracted_data[i][j] < ((extracted_data[i][j-1] * (1-variance_allowed))):\n",
    "                                previous_value=extracted_data[i][j-1]\n",
    "                                extracted_data[i][j] = previous_value\n",
    "                        #check the values against a hardset intensity threshold, which is larger variance, lower threshold\n",
    "                        elif extracted_data[i][j] > (0.25):\n",
    "                            variance_allowed=0.10\n",
    "                            #enforce that the value of the next item cannot drop by more than 10%\n",
    "                            if extracted_data[i][j] < ((extracted_data[i][j-1] * (1-variance_allowed))):\n",
    "                                previous_value=extracted_data[i][j-1]\n",
    "                                extracted_data[i][j] = previous_value\n",
    "            #get the time array\n",
    "            t=extracted_data[0]\n",
    "            return extracted_data,t,extracted_data_original\n",
    "\n",
    "    def km_map_wth_sigmoid(self,xdata,ydata):\n",
    "        try:\n",
    "            popt, pcov = curve_fit(self.curve_func, xdata, ydata)\n",
    "            curve_fit_possible = True\n",
    "        except:\n",
    "            #print 'unable to fit the curve'\n",
    "            curve_fit_possible = False\n",
    "            popt=None\n",
    "            pcov=None    \n",
    "        return curve_fit_possible,popt,pcov    \n",
    "    \n",
    "    def alternate_km_map(self,ydata,t,event_time):\n",
    "        #determine emperically where the ROI sensor hits 50% of the max value\n",
    "        max_value = max(ydata)\n",
    "        for i in range(0,len(ydata)):\n",
    "            #if the value is above half of the max value\n",
    "            if ydata[i] > max_value/2.0:\n",
    "                km=t[i]-event_time\n",
    "                return km\n",
    "        #if the value never exceeds half of the max value\n",
    "        #return the end of the time series\n",
    "        km=t[-1]-event_time\n",
    "        return km\n",
    "    \n",
    "    def train_direction(self,time_before,time_after):\n",
    "        #refresh the video_detector_worker history snapshot\n",
    "        self.get_history_snapshot()\n",
    "        #extracted data is a 5 element array, consisting of\n",
    "        #time, 3 ROIs, and boolean detection events\n",
    "        #with data points corresponding to time before/after detection\n",
    "        timestamp,train_detected_flag = self.identify_frame_of_train_detection()\n",
    "        print timestamp,train_detected_flag \n",
    "        #only proceed if a train was detected in the history dataframe (returns most recent)\n",
    "        if train_detected_flag==True:\n",
    "            event_time=timestamp\n",
    "            extracted_data=self.extract_data_in_time_range(time_before,time_after,event_time)\n",
    "            extracted_data,t,extracted_data_original=\\\n",
    "                self.clean_extracted_data(extracted_data,event_time,self.intensity_threshold)\n",
    "            #create a new figure for plotting and an array to save the event times from each ROI\n",
    "            plt.figure(figsize=(20,8))\n",
    "            time_of_arrival=[]\n",
    "            #calculate the time of arrivel in each ROI \n",
    "            for j in range(1,4):\n",
    "                km,y_curve,x_curve,xdata,ydata,t=self.calculate_time_of_arrival(\n",
    "                                                    extracted_data,j,event_time)\n",
    "                time_of_arrival.append(km)\n",
    "                #Get the normalized time and exact time of arrival - only do this once\n",
    "                if j==1:\n",
    "                    t_adjusted = [t[i] - event_time for i in range(0,len(t))]\n",
    "                    time_string=datetime.datetime.fromtimestamp(event_time).strftime('%Y-%m-%d_%H-%M-%S-%f')\n",
    "                self.plot_for_train_direction(t_adjusted,ydata,x_curve,y_curve,j)\n",
    "                #print 'ROI:',j-1,'time of arrival',km\n",
    "            #decide if the train was going north or south\n",
    "            train_direction=self.decide_train_direction(time_of_arrival)\n",
    "            #format plot \n",
    "            d=extracted_data[4] #to plot the detection event\n",
    "            self.format_entire_plot_for_train_direction(d,t_adjusted,ydata,x_curve,y_curve,\\\n",
    "                    time_before,time_after,train_direction,time_string,time_of_arrival)\n",
    "            #show the figure then return the train direction\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            return train_direction\n",
    "        else:\n",
    "            print 'No train detected'\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Video Detector, determine motion for aReas Of Interest (ROIs), if train passed, and train direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Video_Detector(Thread):\n",
    "    def __init__(self,video_camera,video_sensor,\\\n",
    "                 motion_threshold,time_threshold,cooldown_period):\n",
    "        #Assign objects from the video camera and sensor classes\n",
    "        self.video_camera=video_camera\n",
    "        self.video_sensor=video_sensor\n",
    "        self.input_deque=self.video_camera.input_deque\n",
    "        self.output_deque=self.video_sensor.output_deque\n",
    "        self.fps=self.video_camera.fps\n",
    "        self.framenum_at_train_detection = 0\n",
    "        \n",
    "        #Create ROIs with hardcoded aReas Of Interest (ROIs)\n",
    "        self.create_rois()\n",
    "        \n",
    "        #Assign motion, time and cooldown value \n",
    "        self.motion_threshold=motion_threshold\n",
    "        self.time_threshold=time_threshold #in frames\n",
    "        self.cooldown_period=cooldown_period\n",
    "        \n",
    "        #create circular buffers for train motion, detection events and sampled frames\n",
    "        self.create_buffers()\n",
    "        \n",
    "        #Create the history dataframe\n",
    "        history_object=History(self.fps)\n",
    "        self.history=history_object.setup_history()\n",
    "        \n",
    "        #Create the detector worker for determining train direction, and sample plotting\n",
    "        self.detector_worker=Detector_Worker(video_sensor=self.video_sensor,\n",
    "                                        video_detector=self)\n",
    "        \n",
    "        #start the thread, deamon and kill switch\n",
    "        super(Video_Detector, self).__init__()\n",
    "        self.daemon = True\n",
    "        self.kill_all_threads= False\n",
    "        print self, 'created'\n",
    "     \n",
    "    \n",
    "    def create_rois(self):\n",
    "        #hardcode aReas Of Interest, ROI: ((x1, y1), (x2, y2))\n",
    "        left_roi=((2,80),(50,135))\n",
    "        center_roi=((145,90),(215,130))\n",
    "        right_roi=((325,100),(380,130))\n",
    "        self.all_rois=[left_roi,center_roi,right_roi]\n",
    "        \n",
    "    def create_buffers(self):\n",
    "        #create buffers for detecting if train recently passed and populate with 0s\n",
    "        self.train_detected_buffer=deque(maxlen=self.cooldown_period)\n",
    "        self.train_direction_buffer=deque(maxlen=self.cooldown_period)\n",
    "        #make the motion detected buffer shorter than cooldown_period\n",
    "        #length of motion_detected_buffer determines how time of motion translates into detection\n",
    "        self.motion_detected_buffer=deque(maxlen=self.time_threshold)\n",
    "        #prefill these buffers to max length\n",
    "        for i in range(0,self.cooldown_period):\n",
    "            self.motion_detected_buffer.append(0)\n",
    "            self.train_detected_buffer.append(0)\n",
    "            self.train_direction_buffer.append(0)\n",
    "        #create frame sampler buffer (do not prefill this buffer)\n",
    "        self.frame_sampler_buffer=deque(maxlen=self.cooldown_period)\n",
    "        \n",
    "    def extract_roi_and_process(self,frame_motion):\n",
    "        for v in self.all_rois:\n",
    "            #extract ROI to process from numpy array \n",
    "            #using the x1,y1,x2,y2 coordinates (v)\n",
    "            ROI_to_process= frame_motion[v[0][1]:v[1][1],v[0][0]:v[1][0]]\n",
    "            #get average motion by summing pixel values\n",
    "            #then dividing by total pixels\n",
    "            average_motion_per_roi = ROI_to_process.ravel().sum()\\\n",
    "                // ROI_to_process.ravel().shape[0] \n",
    "            #wait for the background subtractor mask to load before adding motion data\n",
    "            if self.framenum < (5 * self.fps):\n",
    "                average_motion_per_roi=0\n",
    "            #update roi_data array (that will be a future row in the History DF)\n",
    "            self.roi_data.append(average_motion_per_roi)\n",
    "        \n",
    "    def check_motion_and_update_motion_buffer(self):\n",
    "        #check if motion exceeds the defined threshold:\n",
    "        average_motion=reduce(lambda x, y: x + y, self.roi_data[1:4])\\\n",
    "            / len(self.roi_data[1:4])\n",
    "        if average_motion > self.motion_threshold:\n",
    "            self.roi_data.append(True)\n",
    "            self.motion_detected_buffer.append(1)\n",
    "        else:\n",
    "            self.roi_data.append(False)\n",
    "            self.motion_detected_buffer.append(0)\n",
    "            \n",
    "    def save_frame_sampler_to_file(self,data_time,train_direction):\n",
    "        pickle.dump(self.frame_sampler_buffer,open(\"output/persisted_frame_sampler\"+\\\n",
    "                                            data_time+str(train_direction),\"wb\"))\n",
    "        #pickle_object=pickle.load( open(\"persisted_input_queue_20160706_a\",\"rb\"))\n",
    "        \n",
    "    def check_temporal_threshold_and_update_detection_buffer(self,data):\n",
    "        motion_detected_average=reduce(lambda x, y: x + y, self.motion_detected_buffer)\\\n",
    "                /len(self.motion_detected_buffer) \n",
    "        #make sure all frames in motion buffer detected motion\n",
    "        if motion_detected_average >= 1:\n",
    "            #make sure that there has only been 1 train detected in detection buffer\n",
    "            #i.e. that a cooldown period has been passed so trains are flagged only once\n",
    "            if 1 not in self.train_detected_buffer:\n",
    "                #Temporarily update History as well as roi_data for train_detection script\n",
    "                self.roi_data.append(True)\n",
    "                self.roi_data.append('NORTH') #default to NORTH for now\n",
    "                self.history.iloc[self.framenum % self.history.shape[0]] = self.roi_data\n",
    "                #add the positive event to the train_detected buffer\n",
    "                self.train_detected_buffer.append(1)\n",
    "                #DETERMINE TRAIN DIRECTION\n",
    "                train_direction=self.detector_worker.train_direction(time_before=10.0,\n",
    "                                time_after=1.0)\n",
    "                #update the last position of the roi_data, as was already set to True\n",
    "                self.roi_data[-1]=train_direction\n",
    "                #add the train direction to the buffer\n",
    "                self.train_direction_buffer.append(train_direction)\n",
    "                data_time=datetime.datetime.fromtimestamp(\\\n",
    "                    data['time']).strftime('%Y_%m_%d_%H_%M_%S')\n",
    "                print 'Train detected going %s at %s'%(data_time,train_direction)\n",
    "                #save the frame_sampler to file\n",
    "                self.save_frame_sampler_to_file(data_time,train_direction)\n",
    "                #for copying frame_sampler to non-updating version\n",
    "                self.framenum_at_train_detection=self.framenum\n",
    "            else:\n",
    "                self.update_buffers_for_no_train()\n",
    "        else:\n",
    "            self.update_buffers_for_no_train()\n",
    "    \n",
    "    def update_buffers_for_no_train(self):\n",
    "        #As a train was detected in a cooldown period, \n",
    "        #no additional detection or direction event is logged\n",
    "        self.train_detected_buffer.append(0)\n",
    "        self.train_direction_buffer.append(None)\n",
    "        #append roi_data (row for History DF) for train detection event\n",
    "        self.roi_data.append(False)\n",
    "        #append roi_data (row for History DF) for train direction event\n",
    "        self.roi_data.append(None)\n",
    "        \n",
    "    def run(self):\n",
    "        print 'ROI data is now being extracted and persisted'\n",
    "        #keep track of index for inserting data into history df\n",
    "        self.framenum=0\n",
    "        while self.kill_all_threads!=True:\n",
    "            #grab the motion frame (255 is motion, 0 is no motion) \n",
    "            try:\n",
    "                data=self.output_deque.popleft()\n",
    "                frame_motion=data['frame_motion']\n",
    "\n",
    "                #roi_data is an array for appending a row to the History DF \n",
    "                #time of image-capture is first column in History DF \n",
    "                self.roi_data=[data['time']]\n",
    "\n",
    "                #extract ROI to process and get average motion per ROI\n",
    "                self.extract_roi_and_process(frame_motion)\n",
    "\n",
    "                #check if motion exceeds the defined threshold and update buffers,roi_data:\n",
    "                self.check_motion_and_update_motion_buffer()\n",
    "\n",
    "                #check if temporal threshold exceeded for detection (& cooldown not violated)\n",
    "                self.check_temporal_threshold_and_update_detection_buffer(data)\n",
    "\n",
    "                #update the history dataframe and adjust the frame number pointer\n",
    "                self.history.iloc[self.framenum % self.history.shape[0]] = self.roi_data\n",
    "                self.framenum+=1\n",
    "                \n",
    "                #copying frame_sampler to non-updating version\n",
    "                if ((self.framenum_at_train_detection != 0) & (self.framenum==self.framenum_at_train_detection+25)):\n",
    "                    self.frame_sampler_buffer_copy=copy.deepcopy(self.frame_sampler_buffer)\n",
    "\n",
    "                #add frames and data to sampler\n",
    "                self.frame_sampler_buffer.append({\n",
    "                    'frame_raw':data['frame_raw'],\n",
    "                    'frame_motion':data['frame_motion'],\n",
    "                    'time':data['time'],\n",
    "                    'roi_data':self.roi_data,\n",
    "                    'intensity_mean':data['intensity_mean']})\n",
    "                \n",
    "            except IndexError:\n",
    "                #index error occurs when the output_queue is empty\n",
    "                time.sleep(1/self.fps)\n",
    "                pass\n",
    "        \n",
    "        \n",
    "video_detector=Video_Detector(video_camera=video_camera,\n",
    "                              video_sensor=video_sensor,\n",
    "                              motion_threshold=255/4.0, #8 bit camera\n",
    "                              time_threshold=int(video_camera.fps*2), #in frames\n",
    "                              cooldown_period=int(video_camera.fps*10))\n",
    "video_detector.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print properties of system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'mask_type:',video_sensor.mask_type\n",
    "print 'bgsKNN_history:',video_sensor.mask_object.bgsKNN_history\n",
    "print 'bgsKNN_d2T:',video_sensor.mask_object.bgsKNN_d2T\n",
    "print 'bgsKNN_dS:',video_sensor.mask_object.bgsKNN_dS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print video_detector.framenum\n",
    "video_detector.history[200%(int(video_sensor.fps*600)):240%(int(video_sensor.fps*600))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video_detector.detector_worker.train_direction(time_before=10.0,\n",
    "                                time_after=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load input queue from file\n",
    "load_stream_from_file=False\n",
    "if load_stream_from_file==True:\n",
    "    pickle_object=pickle.load( open(\"persisted_input_queue_20160624_b\",\"rb\"))\n",
    "    video_camera.kill_all_threads=True\n",
    "    time.sleep(1)\n",
    "    video_camera.input_deque=pickle_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video_detector.detector_worker.frame_sampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video_detector.detector_worker.video_plotter(total_time_in_plot=video_sensor.fps*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Sampled Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shutdown camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(video_detector.frame_sampler_buffer_copy)):\n",
    "    image_type='frame_motion'\n",
    "    image=video_detector.frame_sampler_buffer_copy[i][image_type]\n",
    "    filename=\"output_video/\"+ image_type + str(i)+\".jpeg\"\n",
    "    plt.figure(figsize=(4,4))\n",
    "    if (image_type==\"frame_raw\"):\n",
    "        plt.imshow(np.flipud(image[:, :, ::-1]))\n",
    "    if (image_type==\"frame_motion\"):\n",
    "        plt.imshow(np.flipud(\\\n",
    "            255-image),\\\n",
    "            cmap='Greys',  interpolation='nearest')\n",
    "    plt.savefig(filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kill=False\n",
    "if kill==True:\n",
    "    kill_all_threads=True\n",
    "    camera.stop_recording()\n",
    "    camera.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2 trainspotting",
   "language": "python",
   "name": "trainspotting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
